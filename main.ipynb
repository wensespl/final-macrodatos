{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdf_paths = glob('./pdfs/*.pdf')\n",
    "pdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "for pdf_path in pdf_paths:\n",
    "    if not os.path.exists(f'images/{pdf_path[7:-4]}'):\n",
    "        os.makedirs(f'images/{pdf_path[7:-4]}')\n",
    "    pages = convert_from_path(pdf_path, 350)\n",
    "    for i, page in enumerate(pages):\n",
    "        page.save(f'./images/{pdf_path[7:-4]}/page_{i}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name_image_list = {}\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_name_image_list[f'{pdf_path[7:-4]}'] = glob(f'./images/{pdf_path[7:-4]}/*.jpg')\n",
    "pdf_name_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "pdfs = r\"./doc1.pdf\"\n",
    "pages = convert_from_path(pdfs, 350)\n",
    "\n",
    "i = 1\n",
    "for page in pages:\n",
    "    image_name = \"Page_\" + str(i) + \".jpg\"  \n",
    "    page.save(image_name, \"JPEG\")\n",
    "    i = i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this command to install open cv2\n",
    "# pip install opencv-python\n",
    "\n",
    "# use this command to install PIL\n",
    "# pip install Pillow\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def mark_region(image_path):\n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,30)\n",
    "\n",
    "    # Dilate to combine adjacent text contours\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
    "\n",
    "    # Find contours, highlight text areas, and extract ROIs\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    line_items_coordinates = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        if y >= 600 and x <= 1000:\n",
    "            if area > 10000:\n",
    "                image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "                line_items_coordinates.append([(x,y), (2200, y+h)])\n",
    "\n",
    "        if y >= 2400 and x<= 2000:\n",
    "            image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "            line_items_coordinates.append([(x,y), (2200, y+h)])\n",
    "\n",
    "\n",
    "    return image, line_items_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Function to process and display each image\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "    else:\n",
    "        ret, thresh1 = cv2.threshold(image, 120, 255, cv2.THRESH_BINARY)\n",
    "        text = pytesseract.image_to_string(thresh1, config='--psm 6')\n",
    "        print(f\"OCR Results for {image_path}:\\n{text}\\n\")\n",
    "        img_rgb = cv2.cvtColor(thresh1, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.show()\n",
    "\n",
    "# List all files in the current directory\n",
    "files = os.listdir('.')\n",
    "\n",
    "# Filter for image files (e.g., .jpg, .jpeg, .png)\n",
    "image_files = [f for f in files if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Process each image file\n",
    "for image_file in image_files:\n",
    "    process_image(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import spacy\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Load the Spanish NLP model\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Convert PDF pages to images\n",
    "pdfs = r\"./doc1.pdf\"\n",
    "pages = convert_from_path(pdfs, 350)\n",
    "\n",
    "# Function to process a single page image and extract text from two columns\n",
    "def process_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    print(f\"Image dimensions: {width}x{height}\")\n",
    "    # Divide the image into two columns\n",
    "    left_col = image[850:3594, :width // 2]\n",
    "    right_col = image[850:3594, width // 2:]\n",
    "\n",
    "    # Convert to binary for better OCR results\n",
    "    ret1, thresh1 = cv2.threshold(left_col, 120, 255, cv2.THRESH_BINARY)\n",
    "    ret2, thresh2 = cv2.threshold(right_col, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # OCR configuration\n",
    "    custom_config = r'--oem 3 --psm 4'\n",
    "\n",
    "    # Extract text from both columns\n",
    "    text_left = str(pytesseract.image_to_string(thresh1, config=custom_config))\n",
    "    text_right = str(pytesseract.image_to_string(thresh2, config=custom_config))\n",
    "\n",
    "    # Combine the text from both columns\n",
    "    text = text_left + \"\\n\" + text_right\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process each page and extract text\n",
    "for i, page in enumerate(pages):\n",
    "    image_name = f\"Page_{i + 1}.jpg\"\n",
    "    page.save(image_name, \"JPEG\")\n",
    "\n",
    "    extracted_text = process_image(image_name)\n",
    "    print(extracted_text)\n",
    "    # Process the extracted text with spaCy\n",
    "    # doc = nlp(extracted_text)\n",
    "    \n",
    "    # Print extracted entities\n",
    "    # for ent in doc.ents:\n",
    "    #     print(\n",
    "    #         f\"\"\"\n",
    "    #         {ent.text = }\n",
    "    #         {ent.start_char = }\n",
    "    #         {ent.end_char = }\n",
    "    #         {ent.label_ = }\n",
    "    #         spacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\"\"\"\n",
    "    #     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
